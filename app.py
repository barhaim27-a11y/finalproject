
import streamlit as st
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load model
model = joblib.load("model.pkl")

# Feature descriptions
feature_descriptions = {
    'MDVP:Fo(Hz)': "×ª×“×™×¨×•×ª ×‘×¡×™×¡×™×ª (Hz)",
    'MDVP:Fhi(Hz)': "×”×ª×“×™×¨×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨ (Hz)",
    'MDVP:Flo(Hz)': "×”×ª×“×™×¨×•×ª ×”× ××•×›×” ×‘×™×•×ª×¨ (Hz)",
    'MDVP:Jitter(%)': "×©×•× ×•×ª ×‘×ª×“×¨ ×”×“×™×‘×•×¨ ×‘××—×•×–×™×",
    'MDVP:Jitter(Abs)': "×©×•× ×•×ª ××•×—×œ×˜×ª ×‘×ª×“×¨",
    'MDVP:RAP': "×©×•× ×•×ª ×ª×“×¨ ×××•×¦×¢×ª",
    'MDVP:PPQ': "××“×“ ×™×¦×™×‘×•×ª ×ª×“×¨ ×××•×¦×¢",
    'Jitter:DDP': "×©×•× ×•×ª ×ª×“×¨ ×›×¤×•×œ×”",
    'MDVP:Shimmer': "×©×•× ×•×ª ×‘×¢×•×¦××ª ×”×§×•×œ",
    'MDVP:Shimmer(dB)': "×©×•× ×•×ª ×‘×¢×•×¦××” ×‘×“×¦×™×‘×œ×™×",
    'Shimmer:APQ3': "×©×•× ×•×ª ×××•×¦×¢×ª ×‘Ö¾3 ××—×–×•×¨×™×",
    'Shimmer:APQ5': "×©×•× ×•×ª ×××•×¦×¢×ª ×‘Ö¾5 ××—×–×•×¨×™×",
    'MDVP:APQ': "×©×•× ×•×ª ×›×œ×œ×™×ª ×‘×¢×•×¦××”",
    'Shimmer:DDA': "×©×•× ×•×ª ×“×™×¤×¨× ×¦×™××œ×™×ª",
    'NHR': "×™×—×¡ ×¨×¢×©/×”×¨××•× ×™×”",
    'HNR': "×™×—×¡ ×”×¨××•× ×™×”/×¨×¢×©",
    'RPDE': "××“×“ ××™Ö¾×“×˜×¨××™× ×™×¡×˜×™×•×ª",
    'DFA': "× ×¤×— ×•×¨×¢×© ×‘×ª×“×™×¨×•×ª × ××•×›×”",
    'spread1': "×¡×˜×™×™×” ××”×ª×“×™×¨×•×ª ×”××™×“×™××œ×™×ª",
    'spread2': "×¡×˜×™×™×” ××•×¨×—×‘×ª",
    'D2': "××™×“×ª ××•×¨×›×‘×•×ª ×©×œ ×”×§×•×œ",
    'PPE': "××“×“ ××§×¨××™×•×ª ×”×§×•×œ"
}

features = list(feature_descriptions.keys())

st.set_page_config(page_title="Parkinson's App", layout="centered")
st.sidebar.title("ğŸ“š × ×™×•×•×˜")
app_mode = st.sidebar.radio("×‘×—×¨ ×¤×¢×•×œ×”:", [
    "ğŸ” ×ª×—×–×™×ª ×‘×•×“×“×ª", 
    "ğŸ“¤ ×—×™×–×•×™ ×œ×¤×™ CSV", 
    "ğŸ“Š ×’×¨×¤×™× ×•×“×©×‘×•×¨×“", 
    "ğŸ” ××™××•×Ÿ ××—×“×©", 
    "â„¹ï¸ ×”×¡×‘×¨ ×¢×œ ×××¤×™×™× ×™×"
])

# ---------------- PAGE 1 ----------------
if app_mode == "ğŸ” ×ª×—×–×™×ª ×‘×•×“×“×ª":
    st.title("ğŸ” ×ª×—×–×™×ª ×‘×•×“×“×ª ×¢× ×”×¡×‘×¨×™×")
    user_input = []
    cols = st.columns(3)
    for i, feature in enumerate(features):
        with cols[i % 3]:
            value = st.number_input(f"{feature}", help=feature_descriptions[feature], value=0.0, format="%0.4f")
            user_input.append(value)
    if st.button("ğŸ”® × ×‘×"):
        X_input = np.array(user_input).reshape(1, -1)
        pred = model.predict(X_input)[0]
        proba = model.predict_proba(X_input)[0][1]
        st.markdown("---")
        if pred == 1:
            st.error(f"âš ï¸ ×—×©×“ ×œ××—×œ×ª ×¤×¨×§×™× ×¡×•×Ÿ | ×¡×‘×™×¨×•×ª: {proba:.2%}")
        else:
            st.success(f"âœ… ××™×Ÿ ×¡×™×× ×™× ×œ××—×œ×ª ×¤×¨×§×™× ×¡×•×Ÿ | ×¡×‘×™×¨×•×ª: {proba:.2%}")
        st.progress(proba)

# ---------------- PAGE 2 ----------------
elif app_mode == "ğŸ“¤ ×—×™×–×•×™ ×œ×¤×™ CSV":
    st.title("ğŸ“¤ ×”×¢×œ××ª ×§×•×‘×¥ CSV")
    uploaded_file = st.file_uploader("×”×¢×œ×” ×§×•×‘×¥ ×¢× ×¤×™×¦'×¨×™×", type=["csv"])
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            missing = set(features) - set(df.columns)
            if missing:
                st.error(f"×—×¡×¨×•×ª ×¢××•×“×•×ª: {', '.join(missing)}")
            else:
                preds = model.predict(df)
                probs = model.predict_proba(df)[:, 1]
                df["Prediction"] = preds
                df["Probability"] = np.round(probs * 100, 2).astype(str) + "%"
                st.success("âœ”ï¸ ×ª×—×–×™×•×ª ×”×•×©×œ××•")
                st.dataframe(df)
                st.download_button("ğŸ“¥ ×”×•×¨×“ ×ª×•×¦××•×ª", data=df.to_csv(index=False), file_name="predictions.csv")
        except Exception as e:
            st.error(f"×©×’×™××”: {e}")

# ---------------- PAGE 3 ----------------
elif app_mode == "ğŸ“Š ×’×¨×¤×™× ×•×“×©×‘×•×¨×“":
    st.title("ğŸ“Š × ×™×ª×•×— ×‘×™×¦×•×¢×™×")
    uploaded = st.file_uploader("ğŸ“¥ ×”×¢×œ×” ×§×•×‘×¥ ×¢× ×¢××•×“×ª 'status'", type="csv")
    if uploaded:
        try:
            df = pd.read_csv(uploaded)
            if "status" not in df.columns:
                st.error("×¢××•×“×ª 'status' × ×“×¨×©×ª")
            else:
                X = df[features]
                y_true = df["status"]
                y_pred = model.predict(X)
                y_prob = model.predict_proba(X)[:, 1]
                fpr, tpr, _ = roc_curve(y_true, y_prob)
                roc_auc = auc(fpr, tpr)

                # ROC
                st.subheader("ğŸ“ˆ ROC Curve")
                fig, ax = plt.subplots()
                ax.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
                ax.plot([0, 1], [0, 1], 'k--')
                ax.set_xlabel("FPR")
                ax.set_ylabel("TPR")
                ax.legend()
                st.pyplot(fig)

                # Confusion matrix
                st.subheader("ğŸ“‰ Confusion Matrix")
                cm = confusion_matrix(y_true, y_pred)
                fig2, ax2 = plt.subplots()
                ConfusionMatrixDisplay(cm).plot(ax=ax2)
                st.pyplot(fig2)

        except Exception as e:
            st.error(f"×©×’×™××”: {e}")

# ---------------- PAGE 4 ----------------
elif app_mode == "ğŸ” ××™××•×Ÿ ××—×“×©":
    st.title("ğŸ” ××™××•×Ÿ ××—×“×© ×©×œ ×”××•×“×œ")
    st.info("×”×¢×œ×” ×§×•×‘×¥ CSV ×¢× ×¢××•×“×ª `status` ×›×“×™ ×œ×××Ÿ ××—×“×© ××ª ×”××•×“×œ.")
    uploaded = st.file_uploader("ğŸ“¥ ×§×•×‘×¥ ××™××•×Ÿ", type="csv")
    if uploaded:
        try:
            df = pd.read_csv(uploaded)
            if "status" not in df.columns:
                st.error("×¢××•×“×ª 'status' ×—×¡×¨×”")
            else:
                X = df[features]
                y = df["status"]
                if st.button("ğŸš€ ×”×ª×—×œ ××™××•×Ÿ"):
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                    pipeline = Pipeline([
                        ("scaler", StandardScaler()),
                        ("clf", RandomForestClassifier(n_estimators=100, random_state=42))
                    ])
                    pipeline.fit(X_train, y_train)
                    acc = accuracy_score(y_test, pipeline.predict(X_test))
                    joblib.dump(pipeline, "model.pkl")
                    st.success(f"âœ… ×”××•×“×œ ×¢×•×“×›×Ÿ | ×“×™×•×§: {acc:.2%}")
        except Exception as e:
            st.error(f"×©×’×™××”: {e}")

# ---------------- PAGE 5 ----------------
elif app_mode == "â„¹ï¸ ×”×¡×‘×¨ ×¢×œ ×××¤×™×™× ×™×":
    st.title("â„¹ï¸ ×”×¡×‘×¨ ×¢×œ ×›×œ ×¤×™×¦'×¨")
    for feature in features:
        st.markdown(f"**{feature}**: {feature_descriptions[feature]}")
